{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data frame loading and transforming data\n",
    "import pandas as pd \n",
    "\n",
    "#For calculations\n",
    "import numpy as np\n",
    "\n",
    "#Computing metrics\n",
    "from scipy import stats\n",
    "\n",
    "#For Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns     #Heat maps and scatter matrix\n",
    "\n",
    "#To Evaluate Model\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats import diagnostic as diag\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "#To build a model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data and replace the '..' with nan\n",
    "econ_df = pd.read_excel('korea_data.xlsx')\n",
    "econ_df = econ_df.replace('..','nan')\n",
    "\n",
    "# set the index to the year column\n",
    "econ_df = econ_df.set_index('Year')\n",
    "\n",
    "# set the data type and select rows up to 2016\n",
    "econ_df = econ_df.astype(float)\n",
    "econ_df = econ_df.loc['1969':'2016']\n",
    "\n",
    "column_names = {'Unemployment, total (% of total labor force) (national estimate)':'unemployment',\n",
    "                'GDP growth (annual %)': 'gdp_growth',\n",
    "                'Gross capital formation (% of GDP)':'gross_capital_formation',\n",
    "                'Population growth (annual %)':'pop_growth', \n",
    "                'Birth rate, crude (per 1,000 people)':'birth_rate',\n",
    "                'Broad money growth (annual %)':'broad_money_growth',                \n",
    "                'Final consumption expenditure (% of GDP)':'final_consum_gdp',\n",
    "                'Final consumption expenditure (annual % growth)':'final_consum_growth',\n",
    "                'General government final consumption expenditure (annual % growth)':'gov_final_consum_growth',\n",
    "                'Gross capital formation (annual % growth)':'gross_cap_form_growth',\n",
    "                'Households and NPISHs Final consumption expenditure (annual % growth)':'hh_consum_growth'}\n",
    "\n",
    "# rename columns\n",
    "econ_df = econ_df.rename(columns = column_names)\n",
    "\n",
    "# check for nulls\n",
    "display('-'*100)\n",
    "display(econ_df.isnull().any())\n",
    "\n",
    "# display the first five rows\n",
    "display('-'*100)\n",
    "display(econ_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Check for multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the correlation matrix\n",
    "corr = econ_df.corr()\n",
    "\n",
    "# display the correlation matrix\n",
    "display(corr)\n",
    "\n",
    "# plot the correlation heatmap\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional Steps: Variance Inflation Factor - quick measure of how much a variable is constributing to the standard error\n",
    "                                            If large, means probably multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define two data frames one before the drop and one after the drop\n",
    "econ_df_before = econ_df\n",
    "econ_df_after = econ_df.drop(['gdp_growth','birth_rate', 'final_consum_growth','gross_capital_formation'], axis = 1)\n",
    "\n",
    "# the VFI does expect a constant term in the data, so we need to add one using the add_constant method\n",
    "X1 = sm.tools.add_constant(econ_df_before)\n",
    "X2 = sm.tools.add_constant(econ_df_after)\n",
    "\n",
    "# create the series for both \n",
    "series_before = pd.Series([variance_inflation_factor(X1.values, i) for i in range(X1.shape[1])], index=X1.columns)\n",
    "series_after = pd.Series([variance_inflation_factor(X2.values, i) for i in range(X2.shape[1])], index=X2.columns)\n",
    "\n",
    "# display the series\n",
    "print('DATA BEFORE')\n",
    "print('-'*100)\n",
    "display(series_before)\n",
    "\n",
    "print('DATA AFTER')\n",
    "print('-'*100)\n",
    "display(series_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Scatter matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the plot\n",
    "pd.plotting.scatter_matrix(econ_df_after, alpha = 1, figsize = (30, 20))\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Describe the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the summary in new variable\n",
    "desc_df = econ_df.describe()\n",
    "\n",
    "# add the standard deviation metric (adding additional rows)\n",
    "desc_df.loc['+3_std'] = desc_df.loc['mean'] + (desc_df.loc['std'] * 3)\n",
    "desc_df.loc['-3_std'] = desc_df.loc['mean'] - (desc_df.loc['std'] * 3)\n",
    "\n",
    "# display it\n",
    "desc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Filtering the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data frame to remove the values exceeding 3 standard deviations\n",
    "econ_remove_df = econ_df[(np.abs(stats.zscore(econ_df)) < 3).all(axis=1)]\n",
    "\n",
    "# what rows were removed\n",
    "econ_df.index.difference(econ_remove_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our input variable (X) & output variable\n",
    "econ_df_after = econ_df.drop(['birth_rate', 'final_consum_growth','gross_capital_formation'], axis = 1)\n",
    "\n",
    "X = econ_df_after.drop('gdp_growth', axis = 1)\n",
    "Y = econ_df_after[['gdp_growth']]\n",
    "\n",
    "# Split X and y into X_\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=1)\n",
    "\n",
    "# create a Linear Regression model object\n",
    "regression_model = LinearRegression()\n",
    "\n",
    "# pass through the X_train & y_train data set\n",
    "regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Explore the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's grab the coefficient of our model and the intercept\n",
    "intercept = regression_model.intercept_[0]\n",
    "coefficent = regression_model.coef_[0][0]\n",
    "\n",
    "print(\"The intercept for our model is {:.4}\".format(intercept))\n",
    "print('-'*100)\n",
    "\n",
    "# loop through the dictionary and print the data\n",
    "for coef in zip(X.columns, regression_model.coef_[0]):\n",
    "    print(\"The Coefficient for {} is {:.2}\".format(coef[0],coef[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get multiple predictions\n",
    "y_predict = regression_model.predict(X_test)\n",
    "\n",
    "# Show the first 5 predictions\n",
    "y_predict[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our intput\n",
    "X2 = sm.add_constant(X)\n",
    "\n",
    "# create a OLS model #(rebuild model using statsmodel which creates a new model)\n",
    "model = sm.OLS(Y, X2)\n",
    "\n",
    "# fit the data\n",
    "est = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 10: Test for heteroscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the White's test\n",
    "_, pval, __, f_pval = diag.het_white(est.resid, est.model.exog, retres = False)\n",
    "print(pval, f_pval)\n",
    "print('-'*100)\n",
    "\n",
    "# print the results of the test\n",
    "if pval > 0.05:\n",
    "    print(\"For the White's Test\")\n",
    "    print(\"The p-value was {:.4}\".format(pval))\n",
    "    print(\"We fail to reject the null hypthoesis, so there is no heterosecdasticity. \\n\")\n",
    "    \n",
    "else:\n",
    "    print(\"For the White's Test\")\n",
    "    print(\"The p-value was {:.4}\".format(pval))\n",
    "    print(\"We reject the null hypthoesis, so there is heterosecdasticity. \\n\")\n",
    "\n",
    "# Run the Breusch-Pagan test\n",
    "_, pval, __, f_pval = diag.het_breuschpagan(est.resid, est.model.exog)\n",
    "print(pval, f_pval)\n",
    "print('-'*100)\n",
    "\n",
    "# print the results of the test\n",
    "if pval > 0.05:\n",
    "    print(\"For the Breusch-Pagan's Test\")\n",
    "    print(\"The p-value was {:.4}\".format(pval))\n",
    "    print(\"We fail to reject the null hypthoesis, so there is no heterosecdasticity.\")\n",
    "\n",
    "else:\n",
    "    print(\"For the Breusch-Pagan's Test\")\n",
    "    print(\"The p-value was {:.4}\".format(pval))\n",
    "    print(\"We reject the null hypthoesis, so there is heterosecdasticity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 11: Check for autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for autocorrelation\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "# calculate the lag, optional\n",
    "lag = min(10, (len(X)//5))\n",
    "print('The number of lags will be {}'.format(lag))\n",
    "print('-'*100)\n",
    "\n",
    "# run the Ljung-Box test for no autocorrelation of residuals\n",
    "# test_results = diag.acorr_breusch_godfrey(est, nlags = lag, store = True)\n",
    "test_results = diag.acorr_ljungbox(est.resid, lags = lag)\n",
    "\n",
    "# grab the p-values and the test statistics\n",
    "ibvalue, p_val = test_results\n",
    "\n",
    "# print the results of the test\n",
    "if min(p_val) > 0.05:\n",
    "    print(\"The lowest p-value found was {:.4}\".format(min(p_val)))\n",
    "    print(\"We fail to reject the null hypthoesis, so there is no autocorrelation.\")\n",
    "    print('-'*100)\n",
    "else:\n",
    "    print(\"The lowest p-value found was {:.4}\".format(min(p_val)))\n",
    "    print(\"We reject the null hypthoesis, so there is autocorrelation.\")\n",
    "    print('-'*100)\n",
    "\n",
    "# plot autocorrelation\n",
    "sm.graphics.tsa.plot_acf(est.resid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 12: Check for normally distributed residuals - checking the mean of the residuals equals zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "\n",
    "# check for the normality of the residuals\n",
    "sm.qqplot(est.resid, line='s')\n",
    "pylab.show()\n",
    "\n",
    "# also check that the mean of the residuals is approx. 0.\n",
    "mean_residuals = sum(est.resid)/ len(est.resid)\n",
    "print(\"The mean of the residuals is {:.4}\".format(mean_residuals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 13: Measures of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# calculate the mean squared error\n",
    "model_mse = mean_squared_error(y_test, y_predict)\n",
    "\n",
    "# calculate the mean absolute error\n",
    "model_mae = mean_absolute_error(y_test, y_predict)\n",
    "\n",
    "# calulcate the root mean squared error\n",
    "model_rmse =  math.sqrt(model_mse)\n",
    "\n",
    "# display the output\n",
    "print(\"MSE {:.3}\".format(model_mse))\n",
    "print(\"MAE {:.3}\".format(model_mae))\n",
    "print(\"RMSE {:.3}\".format(model_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 14: Get R-Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r2 = r2_score(y_test, y_predict)\n",
    "print(\"R2: {:.2}\".format(model_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 15: Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some confidence intervals, 95% by default\n",
    "est.conf_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 16: Get p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the p-values\n",
    "est.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 17: Summary of model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out a summary\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 18: Remove insignificant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our input variable (X) & output variable\n",
    "econ_df_after = econ_df.drop(['birth_rate', 'final_consum_growth','gross_capital_formation','broad_money_growth',\n",
    "                              'unemployment'], axis = 1)\n",
    "\n",
    "X = econ_df_after.drop('gdp_growth', axis = 1)\n",
    "Y = econ_df_after[['gdp_growth']]\n",
    "\n",
    "# Split X and y into X_\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=1)\n",
    "\n",
    "# create a Linear Regression model object\n",
    "regression_model = LinearRegression()\n",
    "\n",
    "# pass through the X_train & y_train data set\n",
    "regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 19: Run new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our intput\n",
    "X2 = sm.add_constant(X)\n",
    "\n",
    "# create a OLS model\n",
    "model = sm.OLS(Y, X2)\n",
    "\n",
    "# fit the data\n",
    "est = model.fit()\n",
    "\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 20: Save model for future use - store in pickle which is storing a python object as a character stream in a file which can be reloaded later to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# pickle the model\n",
    "with open('my_mulitlinear_regression.sav','wb') as f:\n",
    "     pickle.dump(regression_model, f)\n",
    "\n",
    "# load it back in\n",
    "with open('my_mulitlinear_regression.sav', 'rb') as pickle_file:\n",
    "     regression_model_2 = pickle.load(pickle_file)\n",
    "\n",
    "# make a new prediction\n",
    "regression_model_2.predict([X_test.loc[2002]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
